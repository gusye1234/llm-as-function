
<div align="center">
    <a href="https://github.com/gusye1234/gpt-readme">
      <img src="https://img.shields.io/badge/written_by-GPT-green">
    </a>
    <a href="https://github.com/gusye1234/gpt-readme">
      <img src="https://img.shields.io/badge/could_be-Wrong-red">
    </a>
    <a href="https://pypi.org/project/gpt-readme/">
      <img src="https://img.shields.io/pypi/v/gpt-readme.svg">
    </a>
</div>

*This readme is generated by command: `gpt-readme --path ./llm_as_function --exts py --language 中文 --demand llm_as_function is a python module --out see.md`*

# llm_as_function

## Introduction
llm_as_function是一个用于初始化和配置代码库中的LLM（Language Model）功能的Python代码库。它包括子模块和代码文件，提供生成提示、解析输出和与ErnieBot聊天机器人模型交互的功能。

## Get Started
要使用llm_as_function代码库，首先需要安装它。可以按照以下步骤进行安装：
```
pip install llm_as_function
```
安装完成后，可以使用以下命令行参数来使用代码库：
```
python -m llm_as_function
```

## Feature
llm_as_function代码库支持以下主要功能：
- 生成提示：通过调用LLMFunc类的__call__方法生成提示。
- 解析输出：使用LLMFunc类和Final变量存储和操作与提示生成和输出解析相关的数据。
- 与ErnieBot聊天机器人模型交互：通过models模块中的函数与ErnieBot聊天机器人模型进行交互。

以下是主要功能的使用场景和使用方式：
- 生成提示：调用LLMFunc类的__call__方法并传入相应参数来生成提示。
- 解析输出：使用LLMFunc类和Final变量提供的方法和属性来解析输出。
- 与ErnieBot聊天机器人模型交互：使用models模块中的函数创建聊天完成。

## Implementation
llm_as_function代码库由以下代码文件组成：
- llm_as_function/__init__.py：该文件从llm_func模块初始化LLMFunc类的实例，将模型设置为"ernie-bot-4"，温度设置为0.1。
- llm_as_function/llm_func.py：该文件定义了Final和LLMFunc类，用于存储和操作与提示生成和输出解析相关的数据。它还包括一个model_factory函数，用于确定语言模型的类型。主要功能在LLMFunc类的__call__方法中实现。
- llm_as_function/models.py：该文件实现了与ErnieBot聊天机器人模型交互的函数，包括ernie_single_acreate和ernie_single_create用于创建聊天完成。
- llm_as_function/utils.py：该文件提供处理JSON响应、清理输出和生成模式提示的实用函数。它还为代码库设置了日志记录。

## Acknowledgement
llm_as_function代码库使用了以下外部第三方代码库：
- os：提供与操作系统交互的功能。
- json：提供JSON数据的编码和解码功能。
- re：提供正则表达式操作功能。
- typing：提供类型提示功能。
- logging：提供日志记录功能。

感谢以上第三方代码库的贡献。